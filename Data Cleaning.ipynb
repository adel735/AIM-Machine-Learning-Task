{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47130c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c8e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"TextData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53806f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema مبين من كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 يسلملي مرورك وروحك الحلوه💐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 وين هل الغيبه  اخ محمد 🌸🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>458192</td>\n",
       "      <td>1019484980282580992</td>\n",
       "      <td>BH</td>\n",
       "      <td>@Al_mhbaa_7 مبسوطين منك اللي باسطانا😅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>458193</td>\n",
       "      <td>1021083283709407232</td>\n",
       "      <td>BH</td>\n",
       "      <td>@Zzainabali @P_ameerah والله ماينده ابش يختي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>458194</td>\n",
       "      <td>1017477537889431552</td>\n",
       "      <td>BH</td>\n",
       "      <td>@Al_mhbaa_7 شو عملنا لك حنا تهربي مننا احنا مس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>458195</td>\n",
       "      <td>1022430374696239232</td>\n",
       "      <td>BH</td>\n",
       "      <td>@haneenalmwla الله يبارك فيها وبالعافيه 😋😋😋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>458196</td>\n",
       "      <td>1022409931029458944</td>\n",
       "      <td>BH</td>\n",
       "      <td>@jolnar121 السحله ضيفي ي بتطلع لك سحليه😅😅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458197 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                   id dialect  \\\n",
       "0                0  1175358310087892992      IQ   \n",
       "1                1  1175416117793349632      IQ   \n",
       "2                2  1175450108898565888      IQ   \n",
       "3                3  1175471073770573824      IQ   \n",
       "4                4  1175496913145217024      IQ   \n",
       "...            ...                  ...     ...   \n",
       "458192      458192  1019484980282580992      BH   \n",
       "458193      458193  1021083283709407232      BH   \n",
       "458194      458194  1017477537889431552      BH   \n",
       "458195      458195  1022430374696239232      BH   \n",
       "458196      458196  1022409931029458944      BH   \n",
       "\n",
       "                                                     text  \n",
       "0        @Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .  \n",
       "1       @7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...  \n",
       "2                         @KanaanRema مبين من كلامه خليجي  \n",
       "3              @HAIDER76128900 يسلملي مرورك وروحك الحلوه💐  \n",
       "4                      @hmo2406 وين هل الغيبه  اخ محمد 🌸🌺  \n",
       "...                                                   ...  \n",
       "458192              @Al_mhbaa_7 مبسوطين منك اللي باسطانا😅  \n",
       "458193       @Zzainabali @P_ameerah والله ماينده ابش يختي  \n",
       "458194  @Al_mhbaa_7 شو عملنا لك حنا تهربي مننا احنا مس...  \n",
       "458195        @haneenalmwla الله يبارك فيها وبالعافيه 😋😋😋  \n",
       "458196          @jolnar121 السحله ضيفي ي بتطلع لك سحليه😅😅  \n",
       "\n",
       "[458197 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf70e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adelq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36255cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern,input_txt)\n",
    "    for word in r:\n",
    "        input_txt = re.sub(word,\"\",input_txt)\n",
    "        \n",
    "    return input_txt \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('arabic'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b3bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPunc(sentence):\n",
    "    cleaned = re.sub(r'[?|؟|،|:|!|\\'|\"]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|-|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    cleaned = re.sub(r'^هه+', '', cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab08eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f055fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01c71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae173c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = np.vectorize(remove_pattern)(df['text'],\"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e0f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = np.vectorize(remove_emoji)(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a960380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = np.vectorize(remove_stopwords)(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ece139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = np.vectorize(cleanPunc)(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416afdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ee4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790b7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = np.vectorize(remove_URL)(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec01d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = np.vectorize(remove_html)(df['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "278ec263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['clean_text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88654e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Clean_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833c712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
